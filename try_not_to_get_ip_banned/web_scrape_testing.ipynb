{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d432caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef151b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, random\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "# one global session you reuse for all requests\n",
    "def make_session():\n",
    "    s = requests.Session()\n",
    "    # polite headers\n",
    "    s.headers.update({\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/124.0.0.0 Safari/537.36\"\n",
    "        ),\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "    })\n",
    "\n",
    "    # automatic retries with backoff, including 429\n",
    "    retry = Retry(\n",
    "        total=5,                # total retries\n",
    "        connect=3,\n",
    "        read=3,\n",
    "        backoff_factor=1.5,     # exponential backoff: 0, 1.5, 3, 4.5, ...\n",
    "        status_forcelist=(429, 500, 502, 503, 504),\n",
    "        allowed_methods={\"GET\", \"HEAD\"},\n",
    "        respect_retry_after_header=True,   # honors Retry-After on 429/503\n",
    "    )\n",
    "    adapter = HTTPAdapter(max_retries=retry, pool_connections=10, pool_maxsize=10)\n",
    "    s.mount(\"http://\", adapter)\n",
    "    s.mount(\"https://\", adapter)\n",
    "    return s\n",
    "\n",
    "SESSION = make_session()\n",
    "_LAST_REQUEST_TS = 0.0\n",
    "\n",
    "def rate_limit(min_interval=1.1):\n",
    "    \"\"\"Ensure at most ~1 request/second (adjust as needed).\"\"\"\n",
    "    global _LAST_REQUEST_TS\n",
    "    now = time.monotonic()\n",
    "    delta = now - _LAST_REQUEST_TS\n",
    "    if delta < min_interval:\n",
    "        time.sleep(min_interval - delta + random.uniform(0, 0.25))  # small jitter\n",
    "    _LAST_REQUEST_TS = time.monotonic()\n",
    "\n",
    "def get_soup(url, timeout=20):\n",
    "    rate_limit()  # be nice\n",
    "    resp = SESSION.get(url, timeout=timeout)\n",
    "    # If the site still returns 429 without Retry-After, add a manual sleep\n",
    "    if resp.status_code == 429:\n",
    "        # Try to honor Retry-After if present\n",
    "        ra = resp.headers.get(\"Retry-After\")\n",
    "        if ra:\n",
    "            try:\n",
    "                time.sleep(int(ra))\n",
    "            except ValueError:\n",
    "                time.sleep(5)\n",
    "        else:\n",
    "            time.sleep(5 + random.uniform(0, 2))\n",
    "        # one more attempt after cooling down\n",
    "        rate_limit()\n",
    "        resp = SESSION.get(url, timeout=timeout)\n",
    "\n",
    "    resp.raise_for_status()\n",
    "    return BeautifulSoup(resp.text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef57918",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25179d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nba_teams = [\n",
    "#     \"ATL\", \"BOS\", \"BRK\", \"CHI\", \"CLE\", \"DAL\", \"DEN\", \"DET\", \n",
    "#     \"GSW\", \"HOU\", \"IND\", \"LAC\", \"LAL\", \"MEM\", \"MIA\", \"MIL\", \n",
    "#     \"MIN\", \"NOP\", \"NYK\", \"OKC\", \"ORL\", \"PHI\", \"PHO\", \"POR\", \n",
    "#     \"SAC\", \"SAS\", \"TOR\", \"UTA\", \"WAS\", \"CHO\"\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fd24d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.plot(reg_seas_played['Date'], reg_seas_played['MP'])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09cfe9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56238b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get html from urllib\n",
    "def get_soup(url):\n",
    "    try:\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            html = response.read()\n",
    "    except urllib.error.URLError as e:\n",
    "        print(f\"Error fetching URL: {e.reason}\")\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf59d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roster(team_name, season):\n",
    "    '''\n",
    "    Retrieve the roster for a certain season\n",
    "\n",
    "    Args:\n",
    "        team_name - String (ex. CHI, BOS, PHI)\n",
    "        season - String (ex. 2025, 2024)\n",
    "\n",
    "    Returns:\n",
    "        roster - Dataframe\n",
    "    '''\n",
    "\n",
    "    ### call get_html to request data from url\n",
    "    soup = get_soup(f'https://www.basketball-reference.com/teams/{team_name}/{season}.html')\n",
    "\n",
    "    ### extract player names from basketball-reference\n",
    "    cells = soup.select('td[data-stat=\"player\"]')\n",
    "    players = [c.get_text(strip=True) for c in cells]\n",
    "\n",
    "    ### extract player position from basketball-reference\n",
    "    cells = soup.select('td[data-stat=\"pos\"][csk=\"1\"], '\n",
    "                        'td[data-stat=\"pos\"][csk=\"2\"], '\n",
    "                        'td[data-stat=\"pos\"][csk=\"3\"], '\n",
    "                        'td[data-stat=\"pos\"][csk=\"4\"], '\n",
    "                        'td[data-stat=\"pos\"][csk=\"5\"]')\n",
    "    pos = [c.get_text(strip=True) for c in cells]\n",
    "\n",
    "    ### build roster\n",
    "    roster = pd.DataFrame({\n",
    "        'Player_NAME': players,\n",
    "        'Player_POSITION': pos\n",
    "    })\n",
    "\n",
    "    ### add team name \n",
    "    roster['Player_TEAM'] = team_name\n",
    "\n",
    "    return roster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7d9cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = 'hello world'\n",
    "# string.replace('ello', 'fart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4aa77d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game_data(team, opp, url):\n",
    "    '''\n",
    "    Args:\n",
    "        team - String (ex. SAC, LAC)\n",
    "        opp - String (ex. SAC, OKC)\n",
    "        url - String\n",
    "\n",
    "    Returns:\n",
    "        team_df\n",
    "        opp_df\n",
    "    '''\n",
    "    other_url = url\n",
    "    other_url = other_url.replace(team, opp)\n",
    "\n",
    "    print(f'Original URL: {url}')\n",
    "    print(f'Alternate URL: {other_url}')\n",
    "\n",
    "    for attempt in range(1, 3):\n",
    "        time.sleep(0.5 + random.random() * 0.5)\n",
    "        \n",
    "        try:\n",
    "            soup = get_soup(url)\n",
    "        except Exception as ex:\n",
    "            sleep_s = 0.8 * (2 ** (attempt - 1)) + random.random()\n",
    "            time.sleep(sleep_s)\n",
    "            soup = get_soup(other_url)\n",
    "\n",
    "    team_table = soup.select(f'table[id=\"box-{team}-game-basic\"]')\n",
    "    opp_table = soup.select(f'table[id=\"box-{opp}-game-basic\"]')\n",
    "\n",
    "    def parse_box_table(table):\n",
    "        rows = []\n",
    "        for tr in table.select(\"tbody tr\"):\n",
    "            row_data = {}\n",
    "            for cell in tr.select(\"th[data-stat], td[data-stat]\"):\n",
    "                key = cell[\"data-stat\"]\n",
    "                val = cell.get_text(strip=True)\n",
    "                row_data[key] = val\n",
    "            if row_data['player'] == 'Reserves':\n",
    "                continue\n",
    "            rows.append(row_data)\n",
    "        return rows\n",
    "\n",
    "    # Pick the first matching table (since .select returns a list)\n",
    "    team_rows = parse_box_table(team_table[0])\n",
    "    opp_rows  = parse_box_table(opp_table[0])\n",
    "\n",
    "    ### Convert to dataframe\n",
    "    team_df = pd.DataFrame(team_rows)\n",
    "    opp_df = pd.DataFrame(opp_rows)\n",
    "\n",
    "    return team_df, opp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd1afc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_player_data(name, season):\n",
    "    url = f'https://www.basketball-reference.com/players/{name[0]}/{name}/gamelog/{season}/'\n",
    "\n",
    "    soup = get_soup(url)\n",
    "\n",
    "    ### parse html for table data (first 7 rows are useless)\n",
    "    table = soup.find_all('td', class_=['center', 'left', 'right'])[7:]\n",
    "\n",
    "    ### extract the data from the td tags\n",
    "    data_list = []\n",
    "    for i in table:\n",
    "        data = i.get_text(strip=True)\n",
    "\n",
    "        ### account for rows of inactive games\n",
    "        if data.lower() in ['inactive', 'did not dress', 'did not play']:\n",
    "            data_list.append(data)\n",
    "            for _ in range(25):\n",
    "                data_list.append('')\n",
    "        else:\n",
    "            data_list.append(data)\n",
    "\n",
    "    ### format data for dataframe\n",
    "    rows = []\n",
    "    BATCH_SIZE = 33 # 33 columns \n",
    "    for i in range(0, len(data_list), BATCH_SIZE):\n",
    "        curr_data = data_list[i: i+BATCH_SIZE] # row data\n",
    "\n",
    "        rows.append(curr_data)\n",
    "\n",
    "    ### set column names\n",
    "    columns = ['Gcar','Gtm','Date','Team','at','Opp','Result','GS','MP','FG','FGA','FG%','3P','3PA','3P%','2P','2PA','2P%','eFG%','FT','FTA','FT%','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS','GmSc','+/-']\n",
    "\n",
    "    ### create the frame\n",
    "    data = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "    ### separate the final data tables\n",
    "    totals = data[\n",
    "        (data['Gcar'] == '') & \n",
    "        (data['Gtm'] == '') & \n",
    "        (data['Date'] == '') & \n",
    "        (data['Team'] == '') & \n",
    "        (data['at'] == '') & \n",
    "        (data['Opp'] == '')\n",
    "    ].drop(columns=['Gcar', 'Gtm', 'Date', 'Team', 'at', 'Opp'])\n",
    "    reg_season = data.iloc[:totals.index[0]] \n",
    "\n",
    "    ### calculate games missed and played\n",
    "    missed_reg_seas_played = reg_season[reg_season['GS'] != '*'] ### this ###\n",
    "    total_reg_seas_missed_games = len(missed_reg_seas_played)\n",
    "    reg_seas_played = reg_season[reg_season['GS'] == '*'] ### this ###\n",
    "\n",
    "    ### because 3p are 0, their percentage is also gonna be 0 or not reported\n",
    "    ### therefore fill with 0 for any col of %\n",
    "    reg_seas_played[reg_seas_played['3P%'] == '']['3P']\n",
    "    reg_seas_played[reg_seas_played['3P'] == '0'].shape\n",
    "\n",
    "    for col in [c for c in reg_seas_played if '%' in c]:\n",
    "        for row in reg_seas_played.index:\n",
    "            if reg_seas_played.at[row, col] == '':\n",
    "                reg_seas_played.at[row, col] = 0\n",
    "\n",
    "    reg_seas_played = reg_seas_played.drop(columns=['at', 'GS'])\n",
    "\n",
    "    reg_seas_played['Date'] = pd.to_datetime(reg_seas_played['Date']).dt.strftime('%Y%m%d')\n",
    "\n",
    "    result = [1 if r[0] == 'W' else 0 for r in reg_seas_played['Result']]\n",
    "    team_score = [re.findall(r'(?<= )\\d+(?=\\s*-\\s*)', reg_seas_played['Result'][i])[0] for i in reg_seas_played['Result'].index]\n",
    "    opp_score = [re.findall(r'(?<=-)\\s*\\d+', reg_seas_played['Result'][i])[0] for i in reg_seas_played['Result'].index]\n",
    "\n",
    "    reg_seas_played['Result'] = result\n",
    "    reg_seas_played['Team Score'] = team_score\n",
    "    reg_seas_played['Opp Score'] = opp_score\n",
    "\n",
    "    ### convert total mins played to sec\n",
    "    def time_to_secs(time_str):\n",
    "        minutes, seconds = map(int, time_str.split(\":\"))\n",
    "        total_seconds = minutes * 60 + seconds  \n",
    "\n",
    "        return total_seconds\n",
    "\n",
    "    reg_seas_played['MP'] = reg_seas_played['MP'].apply(time_to_secs)\n",
    "\n",
    "    ### calculate what percent of the score was attributed by player\n",
    "    reg_seas_played['Percent Score'] = round(reg_seas_played['PTS'].astype(int) / reg_seas_played['Team Score'].astype(int), 2)\n",
    "\n",
    "    ### convert the data to float values\n",
    "    to_convert = ['FG','FGA','FG%','3P','3PA','3P%','2P','2PA','2P%','eFG%','FT','FTA','FT%','ORB','DRB','TRB','AST','STL','BLK','TOV','PF','PTS','GmSc','+/-', 'Team Score', 'Opp Score']\n",
    "    reg_seas_played[to_convert] = reg_seas_played[to_convert].astype(float)\n",
    "\n",
    "    urls = []\n",
    "    for row in reg_seas_played.index:\n",
    "        curr_data = reg_seas_played.loc[row, :]\n",
    "        curr_team = curr_data['Team']\n",
    "        curr_game_date = curr_data['Date']\n",
    "        game_url = f'https://www.basketball-reference.com/boxscores/{curr_game_date}0{curr_team}.html'\n",
    "\n",
    "        urls.append(game_url)\n",
    "\n",
    "    reg_seas_played['URL'] = urls\n",
    "\n",
    "    data = soup.select('span[itemprop=\"name\"]')\n",
    "\n",
    "    names = []\n",
    "    for i in data:\n",
    "        names.append(i.get_text(strip=True))\n",
    "\n",
    "    name = names[3]\n",
    "\n",
    "    reg_seas_played['Player_NAME'] = name\n",
    "\n",
    "    ### ERROR: WILL TIMEOUT REQUESTS ###\n",
    "\n",
    "    # team_start = []\n",
    "    # opp_start = []\n",
    "    # start = []\n",
    "    # for i in reg_seas_played.index:\n",
    "    #     curr_data = reg_seas_played.iloc[i]\n",
    "\n",
    "    #     team = curr_data['Team']\n",
    "    #     opp = curr_data['Opp']\n",
    "    #     url = curr_data['URL']\n",
    "\n",
    "    #     game_data = get_game_data(team, opp, url)\n",
    "\n",
    "    #     team_starters = list(game_data[0].head()['player'])\n",
    "    #     opp_starters = list(game_data[1].head()['player'])\n",
    "\n",
    "    #     did_start = name in team_starters\n",
    "\n",
    "    #     team_start.append(team_starters)\n",
    "    #     opp_start.append(opp_starters)\n",
    "    #     start.append(did_start)\n",
    "\n",
    "    # reg_seas_played['team_starting_five'] = team_start\n",
    "    # reg_seas_played['opp_starting_five'] = opp_start\n",
    "    # reg_seas_played['starter'] = start\n",
    "\n",
    "    ### ERROR: WILL TIMEOUT REQUESTS ###\n",
    "\n",
    "    return missed_reg_seas_played, reg_seas_played #, player_positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9a62859",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.basketball-reference.com/players/m/murrake02/gamelog/2025/",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m keegan_data = \u001b[43mget_player_data\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmurrake02\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m2025\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m missed_data = keegan_data[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m player_data = keegan_data[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mget_player_data\u001b[39m\u001b[34m(name, season)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_player_data\u001b[39m(name, season):\n\u001b[32m      2\u001b[39m     url = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mhttps://www.basketball-reference.com/players/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/gamelog/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     soup = \u001b[43mget_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m### parse html for table data (first 7 rows are useless)\u001b[39;00m\n\u001b[32m      7\u001b[39m     table = soup.find_all(\u001b[33m'\u001b[39m\u001b[33mtd\u001b[39m\u001b[33m'\u001b[39m, class_=[\u001b[33m'\u001b[39m\u001b[33mcenter\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mright\u001b[39m\u001b[33m'\u001b[39m])[\u001b[32m7\u001b[39m:]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mget_soup\u001b[39m\u001b[34m(url, timeout)\u001b[39m\n\u001b[32m     64\u001b[39m     rate_limit()\n\u001b[32m     65\u001b[39m     resp = SESSION.get(url, timeout=timeout)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BeautifulSoup(resp.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1019\u001b[39m     http_error_msg = (\n\u001b[32m   1020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.basketball-reference.com/players/m/murrake02/gamelog/2025/"
     ]
    }
   ],
   "source": [
    "keegan_data = get_player_data('murrake02', '2025')\n",
    "\n",
    "missed_data = keegan_data[0]\n",
    "player_data = keegan_data[1]\n",
    "# player_positions = keegan_data[2]\n",
    "\n",
    "kings_roster = get_roster('SAC', '2025')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a367787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAC MIN\n",
      "https://www.basketball-reference.com/boxscores/202410240SAC.html https://www.basketball-reference.com/boxscores/202410240MIN.html\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://www.basketball-reference.com/boxscores/202410240MIN.html",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mget_game_data\u001b[39m\u001b[34m(team, opp, url)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     soup = \u001b[43mget_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mget_soup\u001b[39m\u001b[34m(url, timeout)\u001b[39m\n\u001b[32m     65\u001b[39m     resp = SESSION.get(url, timeout=timeout)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BeautifulSoup(resp.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.basketball-reference.com/boxscores/202410240SAC.html",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m opp = data[\u001b[33m'\u001b[39m\u001b[33mOpp\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m url = data[\u001b[33m'\u001b[39m\u001b[33mURL\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m game_data = \u001b[43mget_game_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mteam\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m team_data = game_data[\u001b[32m0\u001b[39m]\n\u001b[32m      9\u001b[39m opp_data = game_data[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 26\u001b[39m, in \u001b[36mget_game_data\u001b[39m\u001b[34m(team, opp, url)\u001b[39m\n\u001b[32m     24\u001b[39m         sleep_s = \u001b[32m0.8\u001b[39m * (\u001b[32m2\u001b[39m ** (attempt - \u001b[32m1\u001b[39m)) + random.random()\n\u001b[32m     25\u001b[39m         time.sleep(sleep_s)\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m         soup = \u001b[43mget_soup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m team_table = soup.select(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtable[id=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbox-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mteam\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-game-basic\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     29\u001b[39m opp_table = soup.select(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mtable[id=\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbox-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m-game-basic\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 67\u001b[39m, in \u001b[36mget_soup\u001b[39m\u001b[34m(url, timeout)\u001b[39m\n\u001b[32m     64\u001b[39m     rate_limit()\n\u001b[32m     65\u001b[39m     resp = SESSION.get(url, timeout=timeout)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[43mresp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BeautifulSoup(resp.text, \u001b[33m\"\u001b[39m\u001b[33mhtml.parser\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\requests\\models.py:1024\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1019\u001b[39m     http_error_msg = (\n\u001b[32m   1020\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1021\u001b[39m     )\n\u001b[32m   1023\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 403 Client Error: Forbidden for url: https://www.basketball-reference.com/boxscores/202410240MIN.html"
     ]
    }
   ],
   "source": [
    "data = player_data.iloc[0]\n",
    "team = data['Team']\n",
    "opp = data['Opp']\n",
    "url = data['URL']\n",
    "\n",
    "game_data = get_game_data(team, opp, url)\n",
    "\n",
    "team_data = game_data[0]\n",
    "opp_data = game_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "700324cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Anthony Edwards',\n",
       " 'Julius Randle',\n",
       " 'Rudy Gobert',\n",
       " 'Jaden McDaniels',\n",
       " 'Mike Conley']"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(opp_data.head()['player'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "a1808d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delay = 0.8\n",
    "# teams = []\n",
    "# opps = []\n",
    "# for i in player_data.index:\n",
    "#     data = player_data.iloc[i]\n",
    "#     team = data['Team']\n",
    "#     opp = data['Opp']\n",
    "#     url = data['URL']\n",
    "\n",
    "#     for attempt in range(1, 3):\n",
    "#         try:\n",
    "#             game_data = get_game_data(team, opp, url)\n",
    "\n",
    "#             team_data = game_data[0]\n",
    "#             opp_data = game_data[1]\n",
    "\n",
    "#             teams.append(team_data)\n",
    "#             opps.append(opp_data)\n",
    "\n",
    "#             time.sleep(0.5 + random.random() * 0.5)\n",
    "#             break\n",
    "# # \n",
    "#         except UnboundLocalError as e:\n",
    "#             if attempt == 2:\n",
    "#                 print(f'Skipping index: {i}')\n",
    "#             else:\n",
    "#                 sleep_s = delay * (2 ** (attempt - 1)) + random.random()\n",
    "#                 time.sleep(sleep_s)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
